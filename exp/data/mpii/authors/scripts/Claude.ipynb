{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c181e3e0-aa70-4d07-b23a-229ad778e20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Claude (Anthropic)\n",
    "# -----------------\n",
    "# Dependencies:\n",
    "#   pip install anthropic\n",
    "#   (Built-in libraries: os, glob, csv, json, sys, time, logging)\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import csv\n",
    "import json\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "# from google.colab import drive  # Removed for Jupyter usage\n",
    "\n",
    "from anthropic import Anthropic\n",
    "\n",
    "# Configure logging to a file named claude.log\n",
    "logging.basicConfig(\n",
    "    filename='/mmfs1/scratch/jacks.local/mali9292/VAD/data/claude.log',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s %(levelname)s: %(message)s'\n",
    ")\n",
    "\n",
    "MAX_RETRIES = 3  # Number of retries on API failure\n",
    "\n",
    "def get_sonnet_response(anthropic_client, prompt, temperature=1, max_tokens=5000):\n",
    "    response = anthropic_client.messages.create(\n",
    "        model=\"claude-3-5-sonnet-20241022\",\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    # The original .text usage was array-based; ensure correct extraction:\n",
    "    return response.content[0].text.strip()\n",
    "\n",
    "def process_csv_files(folder_path, output_json_file, anthropic_client):\n",
    "    \"\"\"\n",
    "    Process all CSV files in a folder. For each CSV:\n",
    "      1) Read the \"Description\" column in order.\n",
    "      2) Construct a single prompt.\n",
    "      3) Call Claude Sonnet with retries on error.\n",
    "      4) Save partial progress in a JSON file so the script can be resumed.\n",
    "      \n",
    "      The JSON key for each file is extracted from the filename\n",
    "      after the last underscore and before the \".csv\" extension.\n",
    "    \"\"\"\n",
    "    # 1) Load existing results (if any) so we can resume from partial progress.\n",
    "    if os.path.exists(output_json_file):\n",
    "        with open(output_json_file, \"r\", encoding=\"utf-8\") as jf:\n",
    "            try:\n",
    "                results = json.load(jf)\n",
    "            except json.JSONDecodeError:\n",
    "                results = {}\n",
    "        logging.info(f\"Loaded existing results from '{output_json_file}'.\")\n",
    "    else:\n",
    "        results = {}\n",
    "        logging.info(f\"No existing '{output_json_file}' found. Starting fresh.\")\n",
    "    \n",
    "    # 2) Get all CSV files\n",
    "    csv_files = sorted(glob.glob(os.path.join(folder_path, \"*.csv\")))\n",
    "    logging.info(f\"Found {len(csv_files)} CSV file(s) in folder '{folder_path}'.\")\n",
    "\n",
    "    # 3) Process each CSV file\n",
    "    for csv_file in csv_files:\n",
    "        # Extract the file ID from the filename\n",
    "        filename = os.path.basename(csv_file)                # e.g. \"0001_American_Beauty_part1_1.csv\"\n",
    "        filename_no_ext = os.path.splitext(filename)[0]      # e.g. \"0001_American_Beauty_part1_1\"\n",
    "        file_id = filename_no_ext.split('_')[-1]             # e.g. \"1\"\n",
    "\n",
    "        # If we've already processed this file_id, skip it (resume logic)\n",
    "        if file_id in results:\n",
    "            logging.info(f\"Skipping file with ID '{file_id}' ('{csv_file}') - already in JSON results.\")\n",
    "            continue\n",
    "        \n",
    "        logging.info(f\"Processing file with ID '{file_id}': '{csv_file}'\")\n",
    "\n",
    "        # Read the CSV and extract the \"Description\" column\n",
    "        descriptions = []\n",
    "        with open(csv_file, newline='', encoding='utf-8') as f:\n",
    "            reader = csv.DictReader(f, delimiter=\",\")\n",
    "            for row_number, row in enumerate(reader, start=1):\n",
    "                if \"Description\" in row:\n",
    "                    description = row[\"Description\"]\n",
    "                    descriptions.append(description)\n",
    "                else:\n",
    "                    logging.info(f\"Warning: 'Description' column not found in row {row_number} of {csv_file}\")\n",
    "\n",
    "        # Build the prompt\n",
    "        prompt = (\n",
    "            \"I have a list of scenes describing a movie in chronological order. Please transform them into a coherent movie description, preserving all events, actions, subjects, and objects. You may apply any or all of the following transformations at your discretion, using your best judgment:  1) Paraphrasing & Varying Language: Use different vocabulary and alter sentence structure from the original text while keeping all information. 2) Active ↔ Passive: Switch active voice to passive or vice versa without losing detail. 3) Brevity: Use fewer words but keep every fact intact. 4) Verbosity: Add descriptive words (no new events) to clarify or emphasize. 5) Micro → Macro / Macro → Micro: Summarize small actions into a bigger overview or break down large actions into step-by-step detail, maintaining the same content. 6) Add or Remove Attributes: Adjust adjectives/adverbs or minor descriptors, but don't remove major content. 7) Express Scenes with Varying Detail: Use fewer words for non-critical moments, and more words for key details. 8) Expand Scenes / Add Emphasis: Elaborate on emotional states or background info, without creating new plot points.  Important: - Maintain chronological order. - Do not omit or alter any essential events or objects. - Feel free to combine transformations if it improves clarity or style. Reply with the output without any de\"\n",
    "            \"Please output only the narrative itself. Do not include any introductory or framing sentences such as \\\"Here's a coherent narrative combining those scenes:\"\n",
    "            \"Input: \\tDescription\\n\"\n",
    "        )\n",
    "        for i, desc in enumerate(descriptions, start=1):\n",
    "            prompt += f\"{i}\\t{desc}\\n\"\n",
    "\n",
    "        # 4) Call Claude Sonnet with retries\n",
    "        attempt = 0\n",
    "        while attempt < MAX_RETRIES:\n",
    "            try:\n",
    "                response = get_sonnet_response(anthropic_client, prompt)\n",
    "                break\n",
    "            except Exception as e:\n",
    "                attempt += 1\n",
    "                logging.info(f\"Error on attempt {attempt} for file ID '{file_id}': {e}\")\n",
    "                if attempt < MAX_RETRIES:\n",
    "                    logging.info(f\"Retrying (attempt {attempt+1}/{MAX_RETRIES})...\")\n",
    "                    time.sleep(3)  # short delay before retry\n",
    "                else:\n",
    "                    # Exceeded max retries, save partial progress and exit\n",
    "                    results[file_id] = f\"Error after {MAX_RETRIES} attempts: {e}\"\n",
    "                    with open(output_json_file, \"w\", encoding='utf-8') as json_file:\n",
    "                        json.dump(results, json_file, indent=4, ensure_ascii=False)\n",
    "                    sys.exit(1)\n",
    "\n",
    "        # 5) Store result in dictionary, keyed by the file_id\n",
    "        results[file_id] = response\n",
    "        logging.info(f\"[File ID '{file_id}'] Stored Claude Sonnet response in results dictionary.\")\n",
    "\n",
    "        # 6) Save partial progress to JSON after each file\n",
    "        with open(output_json_file, \"w\", encoding='utf-8') as json_file:\n",
    "            json.dump(results, json_file, indent=4, ensure_ascii=False)\n",
    "        logging.info(f\"Progress saved after processing file ID '{file_id}'.\")\n",
    "\n",
    "    logging.info(f\"All CSV files processed. Final results have been saved to '{output_json_file}'.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize Anthropic client\n",
    "    anthropic = Anthropic(api_key=\"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\")  # Replace with your Anthropic API key\n",
    "    \n",
    "    # Update paths for your local environment or server\n",
    "    folder_path = \"/mmfs1/scratch/jacks.local/mali9292/VAD/data/NumericTagDataSet/rawGT3_part3\"  # Update to your folder\n",
    "    output_json_file = \"/mmfs1/scratch/jacks.local/mali9292/VAD/data/Authors/authors/GT_part3_claude.json\"\n",
    "\n",
    "    logging.info(\"Starting CSV processing and Claude Sonnet querying...\")\n",
    "    process_csv_files(folder_path, output_json_file, anthropic)\n",
    "    logging.info(\"Processing complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795cf7ae-8fad-4fda-afc4-068ae897ce1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd952683-53ea-4a3b-acc2-cc702cf9b175",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c8c171-1442-4e9c-8d49-464c841dbe91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae86a55-1662-4702-8ffc-9a4ffcf78a6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d43e7ff-b5a9-422a-b87f-83d80fe3e780",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8858c4f0-a09e-448b-8c34-afecab0e41c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353f29c7-7e29-436d-8d1b-87ae3f7f7e03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de48ac8-05af-4192-8a7f-dff67b4e3c37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016de264-3c77-4815-b4b1-470ca1a043f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb646e1c-a520-40a3-8e1d-ccd70557954a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (VAD)",
   "language": "python",
   "name": "vad"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
