{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8ad6c2-d396-4482-a076-122c33fd4830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Base GT - ChatGPT\n",
    "# -------------------------------\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import csv\n",
    "import openai\n",
    "import json\n",
    "import sys\n",
    "import time\n",
    "\n",
    "openai.api_key = \"placeholder\"  # Replace with your actual API key\n",
    "\n",
    "MAX_RETRIES = 3  # Number of retries on API failure\n",
    "\n",
    "def get_gpt4_response(prompt, model=\"gpt-4o\", temperature=1, max_tokens=10000):\n",
    "    \"\"\"\n",
    "    Sends a prompt to GPT-4o and returns the response content or raises an Exception.\n",
    "    \"\"\"\n",
    "    #print(\"\\n[GPT-4o] Sending prompt...\")\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "    )\n",
    "    content = response['choices'][0]['message']['content'].strip()\n",
    "    #print(\"[GPT-4o] Received response:\")\n",
    "    #print(content)\n",
    "    return content\n",
    "\n",
    "def process_csv_files(folder_path, output_json_file):\n",
    "    \"\"\"\n",
    "    Process all CSV files in a folder. For each CSV:\n",
    "      1) Read the \"Description\" column in order.\n",
    "      2) Construct a single prompt.\n",
    "      3) Call GPT-4o with retries on error.\n",
    "      4) Save partial progress in a JSON file so the script can be resumed.\n",
    "    \"\"\"\n",
    "    # 1) Load existing results (if any) so we can resume from partial progress.\n",
    "    if os.path.exists(output_json_file):\n",
    "        with open(output_json_file, \"r\", encoding=\"utf-8\") as jf:\n",
    "            try:\n",
    "                results = json.load(jf)\n",
    "            except json.JSONDecodeError:\n",
    "                # If the file is empty or invalid, start with an empty dictionary\n",
    "                results = {}\n",
    "        print(f\"Loaded existing results from '{output_json_file}'.\")\n",
    "    else:\n",
    "        results = {}\n",
    "        print(f\"No existing '{output_json_file}' found. Starting fresh.\")\n",
    "    \n",
    "    # 2) Get all CSV files\n",
    "    csv_files = sorted(glob.glob(os.path.join(folder_path, \"*.csv\")))\n",
    "    print(f\"Found {len(csv_files)} CSV file(s) in folder '{folder_path}'.\")\n",
    "\n",
    "    # 3) Process each CSV file\n",
    "    for index, csv_file in enumerate(csv_files, start=1):\n",
    "        # Check if we already have a result for this index (resume logic)\n",
    "        if str(index) in results:\n",
    "            print(f\"Skipping file {index} ('{csv_file}') - already in JSON results.\")\n",
    "            continue\n",
    "        \n",
    "        #print(f\"\\nProcessing file {index}: '{csv_file}'\")\n",
    "        descriptions = []\n",
    "\n",
    "        # Read the CSV and extract the \"Description\" column\n",
    "        with open(csv_file, newline='', encoding='utf-8') as f:\n",
    "            # Adjust delimiter if needed (\",\" or \"\\t\", etc.)\n",
    "            reader = csv.DictReader(f, delimiter=\",\")\n",
    "            for row_number, row in enumerate(reader, start=1):\n",
    "                if \"Description\" in row:\n",
    "                    description = row[\"Description\"]\n",
    "                    #print(f\"File {index}, Row {row_number} - Description: {description}\")\n",
    "                    descriptions.append(description)\n",
    "                else:\n",
    "                    print(\n",
    "                        f\"Warning: 'Description' column not found in row {row_number} of {csv_file}\"\n",
    "                    )\n",
    "\n",
    "        # Build the prompt\n",
    "        prompt = (\n",
    "            \"I have a list of scenes describing a movie step by step. \"\n",
    "            \"Please transform them into a single paragraph, preserving the chronological order. \"\n",
    "            \"Include every detail from each scene without adding or omitting any information. \"\n",
    "            \"Use only straightforward, factual wording, and avoid any new or descriptive language beyond what is provided in the scene notes.\\n\\n\"\n",
    "            \"Input: \\tDescription\\n\"\n",
    "        )\n",
    "        for i, desc in enumerate(descriptions, start=1):\n",
    "            prompt += f\"{i}\\t{desc}\\n\"\n",
    "\n",
    "        #print(f\"\\nConstructed prompt for file {index}:\\n{prompt}\")\n",
    "\n",
    "        # 4) Call GPT-4o with retries\n",
    "        attempt = 0\n",
    "        while attempt < MAX_RETRIES:\n",
    "            try:\n",
    "                response = get_gpt4_response(prompt)\n",
    "                # If we get here, we have a successful response\n",
    "                break\n",
    "            except Exception as e:\n",
    "                attempt += 1\n",
    "                #print(f\"Error on attempt {attempt} for file {index}: {e}\")\n",
    "                if attempt < MAX_RETRIES:\n",
    "                    #print(f\"Retrying (attempt {attempt+1}/{MAX_RETRIES})...\")\n",
    "                    time.sleep(3)  # short delay before retry\n",
    "                else:\n",
    "                    # Exceeded max retries, save partial progress and exit\n",
    "                    #print(\"Max retries exceeded. Saving partial progress and exiting.\")\n",
    "                    results[str(index)] = f\"Error after {MAX_RETRIES} attempts: {e}\"\n",
    "                    with open(output_json_file, \"w\", encoding='utf-8') as json_file:\n",
    "                        json.dump(results, json_file, indent=4, ensure_ascii=False)\n",
    "                    sys.exit(1)\n",
    "\n",
    "        # 5) Store result in dictionary\n",
    "        results[str(index)] = response\n",
    "        #print(f\"[File {index}] Stored GPT-4o response in results dictionary.\")\n",
    "\n",
    "        # 6) Save partial progress to JSON after each file\n",
    "        with open(output_json_file, \"w\", encoding='utf-8') as json_file:\n",
    "            json.dump(results, json_file, indent=4, ensure_ascii=False)\n",
    "        print(f\"Progress saved after file {index}.\")\n",
    "\n",
    "    #print(f\"\\nAll CSV files processed. Final results have been saved to '{output_json_file}'.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    folder_path = \"/home/jacks.local/hdubey/VADv6/experiment/rawGT3\"  # Update to your folder\n",
    "    output_json_file = \"GT.json\"\n",
    "\n",
    "    print(\"Starting CSV processing and GPT-4o querying...\")\n",
    "    process_csv_files(folder_path, output_json_file)\n",
    "    print(\"Processing complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (VAD)",
   "language": "python",
   "name": "vad"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
